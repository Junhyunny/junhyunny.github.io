---
title: "검색 증강 생성(RAG, Retrieval-Augmented Generation) LangChain 예제"
search: false
category:
  - ai
  - llms
  - large-language-model
  - langchain
  - rag
  - retrieval-argumented-generation
last_modified_at: 2025-07-27T23:55:00
---

<br/>

#### RECOMMEND POSTS BEFORE THIS

- [LLM 랭체인(LangChain) 예제][lang-chain-link]

## 1. RAG, Retrieval-Augmented Generation

검색 증강 생성(RAG, Retrieval-Augmented Generation)을 알아보기 전에 등장 배경을 알아보자. 

- 지식의 한계
  - 기존 LLM은 학습 시점의 데이터에 기반하여 대답한다. 
  - 모델은 최신 정보나 학습 이후에 발생한 사건들에 대해 알지 못한다.
  - 예를 들어, 2023년까지의 데이터로 학습된 모델은 2024년 이후의 사건들에 대해 답변할 수 없다.
- 환각 문제(hallucination)
  - LLM은 때때로 실제로 존재하지 않는 정보를 생성하는 환각 현상을 보인다.
  - 모델이 학습 데이터에서 패턴을 추출하여 그럴듯한 답변을 하지만, 사실과 다를 수 있다.
  - 예를 들어, 챗GPT는 초기에 세종대왕의 맥북 프로를 던진 사건에 대해 대답했다.
- 출처 추적의 어려움
  - 기존 모델들은 생성한 정보의 출처를 명확히 제시하기 어렵다. 
  - 이는 모델의 답변을 검증하거나 더 자세한 정보를 찾고자 할 때 문제가 된다.
- 도메인 특화 지식의 한계
  - 범용 LLM은 광범위한 주제에 대해 일반적인 지식을 가지고 있지만, 특정 도메인의 심도 있는 전문 지식을 모두 포함하기 어렵다.

검색 증강 생성은 위 문제들을 해결하기 위해 등장했다. 외부에서 실시간으로 검색(retrieval)하고, 이를 바탕으로 답변을 생성(generation)하는 과정을 의미한다. 다음과 같은 과정을 통해 이뤄진다.

1. 검색 단계(retrieval phase)
  - 사용자의 질문이나 컨텍스트를 입력 받아서, 이와 관련된 외부 데이터를 검색한다.
  - 검색 엔진이나 데이터베이스 등 다양한 소스에서 필요한 정보를 찾는다.
2. 문맥 강화 단계(argumentation phase)
3. 생성 단계(generation phase)



## CLOSING

#### TEST CODE REPOSITORY

#### RECOMMEND NEXT POSTS

#### REFERENCE

- <https://brunch.co.kr/@acc9b16b9f0f430/73>
- <https://wikidocs.net/231364>

[lang-chain-link]: https://junhyunny.github.io/ai/large-language-model/langchain/lang-chain/